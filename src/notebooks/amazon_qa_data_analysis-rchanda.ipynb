{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run ../utils/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as C\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables_from_category(category):\n",
    "    with open('../../data/pickle_files/%s.pickle' % category, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "qa_table, reviews_table = tables_from_category(C.VIDEO_GAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question with maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = qa_table['questionText'].str.len() == 20\n",
    "result = qa_table.loc[mask]['questionText']\n",
    "question = result.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset_u = set(stopwords.words('english'))\n",
    "stopset = set([str(sw) for sw in stopset_u])\n",
    "\n",
    "tokens = nltk.word_tokenize(question)\n",
    "tokens = [w.lower() for w in tokens if not w.lower() in stopset]\n",
    "\n",
    "print len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Questions containing \"Read More\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = qa_table['answerText'].str.contains(\"Read More\")\n",
    "result = qa_table.loc[mask]['questionText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsLengthList, questionsLengthList, answersLengthList = generate_length_lists(C.VIDEO_GAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_raw_dataframe(C.VIDEO_GAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = C.LENGTH_DICT[16]\n",
    "C.JSON_DATA_PATH = '../../data/json_data'\n",
    "C.INPUT_DATA_PATH = '../../data/input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_raw_data(item['Category'], item['ReviewLength'], item['QuestionLength'], item['AnswerLength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = get_filter_dataframe(C.VIDEO_GAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"Video_Games\"\n",
    "C.INPUT_DATA_PATH = '../../data/input'\n",
    "with open('%s/train-%s.pickle' % (C.INPUT_DATA_PATH, category), 'rb') as f:\n",
    "    train_data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for questionsList in train_data['questionsList']:\n",
    "    for question in questionsList:\n",
    "        for answer in question['answers']:\n",
    "                print(answer['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import numpy as np\n",
    "from operator import itemgetter, attrgetter\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews1 = [[1,2], [1,2,3],[6,7,8]]\n",
    "reviews2 = [[1], [1,2]]\n",
    "\n",
    "question1 = [1,2,3]\n",
    "question2 = [2,3,4,5]\n",
    "\n",
    "answer1 = [1,3]\n",
    "answer2 = [2]\n",
    "\n",
    "data1 = [(answer1), (answer2)]\n",
    "data2 = [(answer1, question1), (answer2, question2)]\n",
    "data3 = [(answer1, question1, reviews1), (answer2, question2, reviews2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [2]]\n",
      "[([1, 3], [1, 2, 3]), ([2], [2, 3, 4, 5])]\n",
      "[([1, 3], [1, 2, 3], [[1, 2], [1, 2, 3], [6, 7, 8]]), ([2], [2, 3, 4, 5], [[1], [1, 2]])]\n"
     ]
    }
   ],
   "source": [
    "print(data1)\n",
    "print(data2)\n",
    "print(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 3], [2])\n",
      "([1, 2, 3], [2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "a, q = zip(*data2)\n",
    "print(a)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataLoader(DataLoader):\n",
    "\n",
    "    def sortByLength(self, item):\n",
    "        if self.mode is \"1\":\n",
    "            return len(item)\n",
    "        \n",
    "        elif self.mode is \"2\":\n",
    "            assert(len(item) == 2)\n",
    "            return len(item[0])\n",
    "        \n",
    "        elif self.mode is \"3\":\n",
    "            assert(len(item) == 3)\n",
    "            reviews = item[2]\n",
    "            max_len = 0\n",
    "            for review in reviews:\n",
    "                max_len = max(max_len, len(review))\n",
    "            return max_len\n",
    "\n",
    "        \n",
    "    def __init__(self, data, mode, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        sorted(data, key=self.sortByLength, reverse=True)    \n",
    "        self.data = data\n",
    "        \n",
    "\n",
    "    def create_packed_qa(self, batch_data):\n",
    "        batch_data.sort(key=len, reverse=True)\n",
    "        lengths = np.array([len(item) for item in batch_data])\n",
    "        max_len = max(lengths)\n",
    "        \n",
    "        padded_data = np.array( [np.pad(item, (0,max_len-len(item)), 'constant') for item in batch_data] )\n",
    "        padded_data = torch.from_numpy(padded_data)\n",
    "        if torch.cuda.is_available():\n",
    "            padded_data = padded_data.cuda()\n",
    "        padded_data = Variable(padded_data)\n",
    "        \n",
    "        #pack_padded_sequence(padded_data, lengths)\n",
    "        #Size is T*B T=MaxSeqLength, B=BatchSize\n",
    "        return padded_data\n",
    "    \n",
    "    def create_packed_reviews(self, review_data):\n",
    "        max_num_reviews = 0\n",
    "        for reviews in review_data:\n",
    "            max_num_reviews = max(max_num_reviews, len(reviews))\n",
    "        \n",
    "        data = []\n",
    "        for i in range(max_num_reviews):\n",
    "            batch_data = []\n",
    "            for j in range(self.batch_size):\n",
    "                reviews = review_data[j]\n",
    "                if i < len(reviews):\n",
    "                    batch_data.append(reviews[i])\n",
    "                else:\n",
    "                    batch_data.append([0])\n",
    "            data.append(batch_data)\n",
    "        \n",
    "        padded_data = []\n",
    "        for i in range(max_num_reviews):\n",
    "            batch_data = data[i]\n",
    "            max_len = 0\n",
    "            for review in batch_data:\n",
    "                max_len = max(max_len, len(review))\n",
    "            \n",
    "            padded_batch_data = np.array([np.pad(item, (0, max_len-len(item)), 'constant') for item in batch_data])\n",
    "            padded_batch_data = torch.from_numpy(padded_batch_data)\n",
    "            padded_data.append(padded_batch_data)\n",
    "            \n",
    "        return padded_data\n",
    "        \n",
    "    def __iter__(self):\n",
    "        print(self.data)\n",
    "        self.num_batches = len(self.data) // self.batch_size\n",
    "        indices = np.arange(self.num_batches)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for index in indices:\n",
    "            start = index*self.batch_size\n",
    "            end = (index+1)*self.batch_size\n",
    "            \n",
    "            batch_data = self.data[start:end]\n",
    "            assert(self.batch_size == len(batch_data))\n",
    "            \n",
    "            if self.mode is \"1\":\n",
    "                answers = batch_data\n",
    "                packed_answers = self.create_packed_qa(answers)\n",
    "                yield (packed_answers)\n",
    "                \n",
    "            elif self.mode is \"2\":\n",
    "                answers, questions = zip(*batch_data)\n",
    "                packed_answers = self.create_packed_qa(list(answers))\n",
    "                packed_questions = self.create_packed_qa(list(questions))\n",
    "                yield (packed_answers, packed_questions)\n",
    "            \n",
    "            elif self.mode is \"3\":\n",
    "                answers, questions, reviews = zip(*batch_data)\n",
    "                packed_answers = self.create_packed_qa(list(answers))\n",
    "                packed_questions = self.create_packed_qa(list(questions))\n",
    "                packed_reviews = self.create_packed_reviews(list(reviews))\n",
    "                yield (packed_answers, packed_questions, packed_reviews)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = AmazonDataLoader(data3, \"3\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 3], [1, 2, 3], [[1, 2], [1, 2, 3], [6, 7, 8]]), ([2], [2, 3, 4, 5], [[1], [1, 2]])]\n",
      "0 (\n",
      " 1  3\n",
      " 2  0\n",
      "[torch.LongTensor of size (2,2)]\n",
      ", \n",
      " 2  3  4  5\n",
      " 1  2  3  0\n",
      "[torch.LongTensor of size (2,4)]\n",
      ", [\n",
      " 1  2\n",
      " 1  0\n",
      "[torch.LongTensor of size (2,2)]\n",
      ", \n",
      " 1  2  3\n",
      " 1  2  0\n",
      "[torch.LongTensor of size (2,3)]\n",
      ", \n",
      " 6  7  8\n",
      " 0  0  0\n",
      "[torch.LongTensor of size (2,3)]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(data_loader):\n",
    "    print(batch_idx, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByMaxReviewLength(item):\n",
    "    reviews = item[2]\n",
    "    max_len = 0\n",
    "    for review in reviews:\n",
    "        max_len = max(max_len, review.shape[0])\n",
    "    return max_len\n",
    "\n",
    "for item in data3:\n",
    "    assert(len(item) == 3)\n",
    "\n",
    "sorted(data3, key=sortByMaxReviewLength, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByAnswerLength(item):\n",
    "    return item[0].shape[0]\n",
    "\n",
    "sorted(data2, key=sortByAnswerLength, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = data1\n",
    "print(answers)\n",
    "\n",
    "answers, questions = zip(*data2)\n",
    "print(data2)\n",
    "print(answers)\n",
    "print(questions)\n",
    "\n",
    "answers, questions, reviews = zip(*data3)\n",
    "print(data3)\n",
    "print(answers)\n",
    "print(questions)\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.randn(10, 10, 30))\n",
    "lens = list(range(1, 11))\n",
    "x = pack_padded_sequence(x, lens[::-1], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=\n",
       "-3.4826  0.6505  0.2313  ...  -0.4217 -1.1333  0.5225\n",
       " 0.7663  0.1747 -1.2382  ...   1.3020 -0.6078  1.3379\n",
       " 1.6234  1.1971  1.0253  ...   0.8074  0.5033  0.2730\n",
       "          ...             ⋱             ...          \n",
       " 0.7317  0.5685  0.3223  ...   0.4950  1.7678 -0.1372\n",
       "-0.5602  0.9418 -0.2048  ...  -0.1512 -0.6764  0.9189\n",
       "-0.2069 -0.3963 -0.1961  ...   0.7188  1.9704 -0.1466\n",
       "[torch.FloatTensor of size (55,30)]\n",
       ", batch_sizes=\n",
       " 10\n",
       "  9\n",
       "  8\n",
       "  7\n",
       "  6\n",
       "  5\n",
       "  4\n",
       "  3\n",
       "  2\n",
       "  1\n",
       "[torch.LongTensor of size (10,)]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_packed_sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " (0 ,.,.) = \n",
       "  -3.4826  0.6505  0.2313  ...  -0.4217 -1.1333  0.5225\n",
       "   0.7663  0.1747 -1.2382  ...   1.3020 -0.6078  1.3379\n",
       "   1.6234  1.1971  1.0253  ...   0.8074  0.5033  0.2730\n",
       "            ...             ⋱             ...          \n",
       "   1.8438 -0.5399  0.7004  ...  -1.6241 -2.0630  0.3565\n",
       "  -0.2727 -0.5130  0.5228  ...  -0.3009  0.3447 -0.3301\n",
       "   1.5795 -0.6392 -0.2103  ...   1.4226  1.4350 -1.3024\n",
       " \n",
       " (1 ,.,.) = \n",
       "  -0.0898 -1.7344 -1.4330  ...  -0.7859 -0.2026  1.6404\n",
       "   1.4913 -1.1662  0.1572  ...   1.5091 -0.9296  0.7801\n",
       "   1.3479  0.1117  0.7511  ...  -2.1069 -0.1227 -0.3189\n",
       "            ...             ⋱             ...          \n",
       "   0.5413 -1.7192  1.3961  ...  -0.9017 -0.2772 -0.4945\n",
       "   1.8068 -1.0969 -2.0279  ...  -1.4663  0.8353  0.0754\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " \n",
       " (2 ,.,.) = \n",
       "  -1.0612  0.3370  0.7215  ...   0.1293 -0.0694 -1.4525\n",
       "   0.1806  0.7922  0.4486  ...  -1.3753  0.4514  0.1990\n",
       "   0.4137  1.0701  0.2034  ...   0.3928 -1.0111 -0.0325\n",
       "            ...             ⋱             ...          \n",
       "  -1.4080  0.1834  0.5745  ...   0.1031  0.4547  0.0436\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " ...\n",
       " \n",
       " (7 ,.,.) = \n",
       "   0.4584 -0.7776 -0.3216  ...  -0.5484 -0.4045  0.3943\n",
       "  -0.3596  0.9344 -0.4472  ...  -0.2029  0.3252 -0.4123\n",
       "  -0.1885 -0.3291  0.4490  ...  -0.2237  1.3379  0.6917\n",
       "            ...             ⋱             ...          \n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " \n",
       " (8 ,.,.) = \n",
       "   0.7317  0.5685  0.3223  ...   0.4950  1.7678 -0.1372\n",
       "  -0.5602  0.9418 -0.2048  ...  -0.1512 -0.6764  0.9189\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "            ...             ⋱             ...          \n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " \n",
       " (9 ,.,.) = \n",
       "  -0.2069 -0.3963 -0.1961  ...   0.7188  1.9704 -0.1466\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "            ...             ⋱             ...          \n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " [torch.FloatTensor of size (10,10,30)], \n",
       "  10\n",
       "   9\n",
       "   8\n",
       "   7\n",
       "   6\n",
       "   5\n",
       "   4\n",
       "   3\n",
       "   2\n",
       "   1\n",
       " [torch.LongTensor of size (10,)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
